# üìã Project Summary

## ‚úÖ What Has Been Created

This is a **complete, production-ready local RAG (Retrieval-Augmented Generation) system** that processes large documents and answers questions using AI ‚Äî completely private and offline.

### üèóÔ∏è Complete System Architecture

#### 1. **Core Application** (`app/`)
- `main.py` - FastAPI server with `/api/*` endpoints
- `rag_backend.py` / `rag_backend_2026.py` - RAG logic, retrieval, routing, compression
- `templates/index.html` - Glassmorphism UI

#### 2. **Document Processing** (Two-Phase System)
- `phase1_extract.py` - Memory-efficient extraction to JSONL; optional OCR
- `phase2_embed.py` - Chunking + embeddings + LanceDB storage; resumable; optional translation

#### 3. **Retrieval & Indexing**
- LanceDB vector store in `./data/index` (table `docs`)
- BM25 keyword index built from LanceDB via `build_bm25_index.py`
- Hybrid retrieval (BM25 + vector) with ranking fusion

#### 4. **Configuration**
- `.env` - Feature flags and tuning (hybrid search/routing/compression + LM Studio)

---

## üéØ Key Features Implemented

1. **‚úÖ Two-Phase Processing**
   - Phase 1: extraction (page-by-page, memory-safe)
   - Phase 2: chunking + embeddings (resumable, incremental)

2. **‚úÖ 2026 Retrieval Upgrades (enabled via `.env`)**
   - Hybrid search (BM25 + vector)
   - Query routing
   - Context compression
   - Conversation memory + query decomposition modules available

3. **‚úÖ OCR Support (for scanned PDFs)**
   - `phase1_extract.py --ocr` uses PyMuPDF rendering ‚ûú Tesseract OCR
   - `--ocr-lang` supports language selection (e.g., `san` for Sanskrit)

4. **‚úÖ Optional Ingestion-time Translation (for non-English OCR)**
   - `phase2_embed.py` can translate chunks before embedding (LM Studio OpenAI-compatible API)
   - Controlled via `.env` flags:
     - `TRANSLATE_NON_ENGLISH=true`
     - `TRANSLATE_ONLY_FILES=...`
     - `TRANSLATION_TARGET_LANG=en`
     - `TRANSLATION_MODEL=local-model`

---

## üöÄ How to Use

```bash
# 1) Setup
./setup.sh

# 2) Extract + embed
python phase1_extract.py --all
python phase2_embed.py --all

# OCR example
python phase1_extract.py --all --ocr --ocr-lang san
python phase2_embed.py --all

# 3) Build BM25 after ingestion
python build_bm25_index.py

# 4) Start (with LM Studio running)
./run.sh
```

---

## ‚úÖ Notes on Endpoints

Current FastAPI endpoints are under `/api/*`:
- Health: `/api/health`
- Ask: `/api/ask`
- Stats: `/api/stats`

Some older docs reference `/status` or `/query`.
