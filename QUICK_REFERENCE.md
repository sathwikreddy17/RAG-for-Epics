# ðŸš€ Quick Reference Card

## Local RAG System - One-Page Cheat Sheet

**System Status**: âœ… Running on http://localhost:8000  
**Current Model**: openai/gpt-oss-20b  
**Database**: 9,199 chunks ready  

---

## ðŸ“‹ Essential Commands

### Start/Stop
```bash
# Start everything (smart startup with checks)
./start_everything.sh

# Stop server
pkill -f 'uvicorn app.main:app'

# Restart (stop + start)
pkill -f 'uvicorn app.main:app' && ./start_everything.sh
```

### Check Status
```bash
# Health check
curl http://localhost:8000/api/health | python3 -m json.tool

# View logs (live)
tail -f server.log

# View logs (last 50 lines)
tail -50 server.log

# Check if server is running
lsof -i :8000
```

### Process Documents
```bash
# Batch process all documents
./auto_pipeline.sh

# Enable automatic processing (runs in background)
./watch_and_process.sh

# Process single file manually
python3 phase1_extract.py --file documents/your_file.pdf
python3 phase2_embed.py --file documents/extracted_text/your_file_pages.jsonl
```

---

## ðŸŒ Access URLs

| Service | URL | Purpose |
|---------|-----|---------|
| **Frontend** | http://localhost:8000 | Ask questions |
| **Health API** | http://localhost:8000/api/health | Check status |
| **Stats API** | http://localhost:8000/api/stats | Get metrics |
| **LM Studio** | http://localhost:1234 | LLM server |

---

## ðŸ“ Important Directories

```
Codebase/
â”œâ”€â”€ documents/              â† Drop PDFs here
â”œâ”€â”€ documents/extracted_text/  â† JSONL files (auto-generated)
â”œâ”€â”€ data/index/docs.lance/    â† Vector database
â”œâ”€â”€ server.log                â† Server logs
â”œâ”€â”€ watcher.log               â† File watcher logs
â””â”€â”€ app/templates/            â† Frontend UI
```

---

## ðŸ”§ Common Tasks

### Add New Documents
```bash
# Option 1: Automatic (recommended)
./watch_and_process.sh    # Run once, leave running
# Then drop PDFs in documents/ folder

# Option 2: Manual
cp your_new.pdf documents/
./auto_pipeline.sh
```

### Query the System
1. Open http://localhost:8000
2. Type your question
3. Check "Show sources" for references
4. Click "Ask Question"
5. View answer with source citations

### Check Database
```bash
# Get stats via API
curl -s http://localhost:8000/api/stats | python3 -m json.tool

# Count chunks manually
python3 -c "import lancedb; db = lancedb.connect('./data/index'); print(len(db.open_table('docs')))"
```

---

## ðŸ› Troubleshooting

### Server Won't Start
```bash
# Check if LM Studio is running
curl http://localhost:1234/v1/models

# If not, open LM Studio â†’ Load model â†’ Start server

# Check port availability
lsof -i :8000

# If occupied, kill process
kill -9 $(lsof -t -i:8000)
```

### No Results for Questions
```bash
# Check if documents are processed
curl http://localhost:8000/api/stats

# If database is empty, process documents
./auto_pipeline.sh

# Check server logs
tail -20 server.log
```

### LM Studio Connection Failed
```bash
# Verify LM Studio is running
curl http://localhost:1234/v1/models

# If not responding:
# 1. Open LM Studio app
# 2. Go to "Local Server" tab
# 3. Click "Start Server"
# 4. Wait for green indicator
# 5. Restart RAG system
./start_everything.sh
```

### Processing Stuck
```bash
# Check watcher logs
tail -f watcher.log

# Check for marker files (indicates processing)
ls -la documents/*.processing

# If stuck, remove markers and retry
rm documents/*.processing
./auto_pipeline.sh
```

---

## ðŸ“Š System Information

### Current Configuration
```bash
# View configuration
cat .env

# Key settings
LANCEDB_PATH=./data/index
EMBEDDING_MODEL=BAAI/bge-large-en-v1.5
USE_RERANKER=false
TOP_K_INITIAL=10
TOP_K_FINAL=5
STRICT_MODEL_CHECK=false  # Any model works!
```

### Resource Usage
```bash
# Check server process
ps aux | grep uvicorn

# Check disk usage
du -sh data/index/

# Check memory
top -pid $(pgrep -f uvicorn)
```

---

## ðŸŽ¯ Quick Checks

### Is Everything Running?
```bash
# 1. LM Studio running?
curl -s http://localhost:1234/v1/models && echo "âœ… LM Studio OK" || echo "âŒ LM Studio DOWN"

# 2. RAG Server running?
curl -s http://localhost:8000/api/health && echo "âœ… Server OK" || echo "âŒ Server DOWN"

# 3. Database has data?
curl -s http://localhost:8000/api/stats | grep -q "total_chunks" && echo "âœ… Database OK" || echo "âŒ Database EMPTY"
```

### Full System Check
```bash
# Use smart startup (does all checks)
./start_everything.sh
# If all âœ…, system is ready!
```

---

## ðŸ”‘ Key Features

### 1. Zero Hallucinations
- System only answers from documents
- Refuses to answer "Hi" (no relevant data)
- Provides sources for every claim

### 2. Smart Startup
- 7 pre-flight checks
- Clear error messages
- Only starts if everything is ready

### 3. Hot-Reload
- Add documents without restart
- System detects changes automatically
- Zero downtime

### 4. Beautiful UI
- Modern glassmorphism design
- Real-time source display
- Confidence scores

---

## ðŸ“– Documentation Quick Links

| Document | Purpose | Read Time |
|----------|---------|-----------|
| **STARTUP_GUIDE.md** | How to start | 15 min |
| **COMPLETE_DOCUMENTATION.md** | Everything | 60 min |
| **TECHNICAL_ARCHITECTURE.md** | Deep dive | 45 min |
| **AUTOMATION_QUICK_REF.md** | Automation | 10 min |
| **DOCUMENTATION_INDEX.md** | Doc guide | 5 min |

---

## âš¡ Pro Tips

### Faster Queries
```bash
# In .env, adjust these:
TOP_K_FINAL=3           # Fewer sources = faster
USE_RERANKER=false      # Already disabled
```

### Better Accuracy
```bash
# In .env:
TOP_K_FINAL=10          # More sources = better context
USE_RERANKER=true       # Rerank for relevance
```

### Monitor Performance
```bash
# Watch logs in real-time
tail -f server.log | grep "Answer generated"

# See query times
grep "duration" server.log
```

### Backup Database
```bash
# Simple backup
tar -czf backup-$(date +%Y%m%d).tar.gz data/index/ documents/

# Restore if needed
tar -xzf backup-20260108.tar.gz
```

---

## ðŸŽ¨ Frontend Tips

### Ask Good Questions
âœ… **Good**: "What is the Mahabharata?"  
âŒ **Bad**: "Hi"  

âœ… **Good**: "Who are the main characters?"  
âŒ **Bad**: "Tell me a joke"  

**Why**: System only has your documents, not general knowledge!

### Interpret Confidence Scores
- **>70%**: Highly relevant, trust this source
- **50-70%**: Moderately relevant
- **<50%**: Weak match, verify carefully

### Use Source Links
- Click on source cards to see exact text
- Note page numbers for verification
- Check multiple sources for confirmation

---

## ðŸ†˜ Emergency Commands

### System Completely Broken
```bash
# Nuclear option: restart everything
pkill -f uvicorn
pkill -f watch_documents.py
rm data/.reload_trigger
./start_everything.sh
```

### Database Corrupted
```bash
# Rebuild from scratch
rm -rf data/index/
./auto_pipeline.sh
# Wait for processing to complete
```

### Lost All Documents
```bash
# Restore from backup
tar -xzf backup-latest.tar.gz
./start_everything.sh
```

---

## ðŸ“± Mobile Access

### Access from Phone/Tablet
```bash
# Find your Mac's IP address
ifconfig | grep "inet " | grep -v 127.0.0.1

# Access from mobile browser
http://<your-ip>:8000
```

---

## âœ… Daily Checklist

**Morning Startup**:
- [ ] Open LM Studio
- [ ] Load model (if not auto-loaded)
- [ ] Run `./start_everything.sh`
- [ ] Verify http://localhost:8000 loads

**During Use**:
- [ ] Drop new PDFs in documents/
- [ ] Wait for processing (if watcher running)
- [ ] OR run `./auto_pipeline.sh` manually

**End of Day**:
- [ ] Check logs for errors: `tail -20 server.log`
- [ ] Optional: Stop server to save resources
- [ ] LM Studio can stay running

---

## ðŸŽ‰ You're Ready!

**Start Command**: `./start_everything.sh`  
**Frontend**: http://localhost:8000  
**Docs**: STARTUP_GUIDE.md  

**Need Help?**  
1. Check STARTUP_GUIDE.md troubleshooting
2. View server.log
3. Run health check

**Everything Working?**  
Start asking questions about your documents! ðŸš€

---

**System Version**: 1.0.0  
**Status**: Production Ready âœ…  
**Hallucinations**: Zero ðŸŽ¯  

*Print this page for quick reference!*
