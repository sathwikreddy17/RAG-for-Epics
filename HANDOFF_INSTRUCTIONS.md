# ðŸ”„ RAG System Handoff Instructions

> **Copy everything below this line into a new chat to continue development**

---

## Project Context

I'm working on a **local-first RAG (Retrieval-Augmented Generation) system** for querying large document corpora (primarily Indian epic texts like Ramayana). The system is fully functional with 16 features implemented.

### Quick Start Commands
```bash
cd "/Users/sathwikreddy/Projects/Model Training/Codebase"
source venv_rag_2026/bin/activate
uvicorn app.main:app --host 0.0.0.0 --port 8000
# Open http://localhost:8000
# Requires: LM Studio running at localhost:1234
```

---

## Current State (January 11, 2026)

### âœ… All 16 Features Working

| # | Feature | File(s) | Status |
|---|---------|---------|--------|
| 1 | Hybrid Search | `app/hybrid_search.py`, `app/bm25_index.py` | âœ… |
| 2 | Query Routing | `app/query_router.py` | âœ… |
| 3 | Context Compression | `app/context_compressor.py` | âœ… |
| 4 | Reranking | `app/rag_backend.py` (CrossEncoder) | âœ… |
| 5 | Quality Filtering | `app/rag_backend.py` | âœ… |
| 6 | Evidence Extraction | `app/evidence_extractor.py` | âœ… |
| 7 | Diversity/MMR | `app/diversity_ranker.py` | âœ… |
| 8 | Query Decomposition | `app/query_decomposer.py` | âœ… |
| 9 | Feedback Collection | `app/main.py` | âœ… |
| 10 | Response Cache | `app/rag_backend.py` | âœ… |
| 11 | Spelling Suggestions | `app/spelling_suggester.py` | âœ… |
| 12 | Expandable Sources | `app/templates/index.html` | âœ… |
| 13 | Source Text Highlighting | `app/text_highlighter.py` | âœ… |
| 14 | Export Results | `app/result_exporter.py` | âœ… |
| 15 | Streaming Responses | `app/rag_backend.py`, `app/main.py` | âœ… |
| 16 | **Query History** | `app/query_history.py` | âœ… NEW |

### Recent Bug Fixes (This Session)
1. **Context Length Overflow** - Added `MAX_CONTEXT_CHARS=6000`, smart truncation
2. **LLM Hallucination** - Strict system prompt, temperature 0.05

### New Features Added (This Session)
1. **Source Text Highlighting** - Query terms highlighted in source passages
2. **Export Results** - Download answer + sources as Markdown/HTML/JSON
3. **Streaming Responses** - Real-time LLM output via SSE
4. **Query History** - Stores and manages recent queries with sidebar UI

### Tech Stack
- **Backend:** FastAPI (`app/main.py`)
- **RAG Core:** `app/rag_backend.py`
- **Vector DB:** LanceDB (`./data/index`, 18,791 chunks)
- **Embeddings:** sentence-transformers (all-MiniLM-L6-v2)
- **Reranker:** cross-encoder/ms-marco-MiniLM-L-6-v2
- **LLM:** LM Studio (localhost:1234)
- **Frontend:** `app/templates/index.html` (glassmorphism UI)
- **Spelling Index:** 11,864 entities in `./data/spelling/entities.json`

---

## Key Files to Know

```
app/
â”œâ”€â”€ main.py              # FastAPI endpoints
â”œâ”€â”€ rag_backend.py       # Core RAG pipeline (+ streaming)
â”œâ”€â”€ spelling_suggester.py # Name variation handling
â”œâ”€â”€ text_highlighter.py  # Query term highlighting (NEW)
â”œâ”€â”€ result_exporter.py   # Export to MD/HTML/JSON (NEW)
â”œâ”€â”€ hybrid_search.py     # BM25 + Vector search
â”œâ”€â”€ query_decomposer.py  # Complex query breakdown
â””â”€â”€ templates/
    â””â”€â”€ index.html       # Frontend UI (streaming + export)

data/
â”œâ”€â”€ index/               # LanceDB vectors
â”œâ”€â”€ bm25_index/          # BM25 keyword index
â”œâ”€â”€ spelling/            # Entity index for autocomplete
â””â”€â”€ exports/             # Exported results (NEW)
```

---

## API Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/ask` | POST | Main Q&A endpoint |
| `/api/ask/stream` | POST | **Streaming Q&A (SSE)** âœ… NEW |
| `/api/highlight` | POST | **Highlight query terms** âœ… NEW |
| `/api/export` | POST | **Export to MD/HTML/JSON** âœ… NEW |
| `/api/autocomplete` | GET | Typing suggestions |
| `/api/spelling/suggest` | GET | Spelling corrections |
| `/api/spelling/stats` | GET | Index statistics |
| `/api/health` | GET | Health check |
| `/api/feedback` | POST | User feedback |

---

## Configuration (.env)

```bash
LM_STUDIO_URL=http://localhost:1234/v1
LLM_TEMPERATURE=0.05
MAX_CONTEXT_CHARS=6000
HYBRID_SEARCH_ENABLED=true
HYBRID_ALPHA=0.7
```

---

## Documentation Files

- `FULL_SYSTEM_DOCUMENTATION.md` - Complete A-Z docs
- `README.md` - Quick overview
- `CHANGELOG.md` - Version history

---

## Potential Next Features (Prioritized)

### High Priority
1. **Chapter/Verse Navigation** - Browse by book structure
2. **Multi-document Comparison** - Compare across texts
3. **Query History** - Recent queries sidebar

### Medium Priority
4. **Bookmarks** - Save interesting passages
5. **Voice Input** - Speech-to-text queries
6. **Mobile Responsive** - Better small screen UI
7. **Dark/Light Theme Toggle**

### Low Priority
8. **Batch Query Processing** - Process multiple questions at once
9. **Citation Generation** - Generate proper academic citations
10. **Language Detection** - Auto-detect and handle Sanskrit/Hindi

---

## Known Working Examples

**Test Queries:**
- "Who is Rama?" â†’ Works, good answer
- "Who is Meghanada?" â†’ Works, correct identification as Ravana's son
- "meganath" â†’ Autocomplete suggests "Meghanada" âœ…
- "What do you know about Kaikeyi?" â†’ Works (was fixed this session)

**Test Autocomplete:**
```bash
curl "http://localhost:8000/api/autocomplete?q=Ram&limit=5"
```

**Test Spelling:**
```bash
curl "http://localhost:8000/api/spelling/suggest?query=meganath"
```

**Test Streaming (NEW):**
```bash
curl -X POST "http://localhost:8000/api/ask/stream" \
  -H "Content-Type: application/json" \
  -d '{"question": "Who is Rama?", "include_sources": true}'
```

**Test Export (NEW):**
```bash
curl -X POST "http://localhost:8000/api/export" \
  -H "Content-Type: application/json" \
  -d '{"query": "Who is Rama?", "answer": "Rama is...", "sources": [], "format": "markdown"}' \
  -o export.md
```

**Test Highlighting (NEW):**
```bash
curl -X POST "http://localhost:8000/api/highlight" \
  -H "Content-Type: application/json" \
  -d '{"text": "Rama was the prince of Ayodhya", "query": "Who is Rama?"}'
```

---

## How to Continue

1. Start the server (commands above)
2. Open http://localhost:8000
3. Review `FULL_SYSTEM_DOCUMENTATION.md` for details
4. Pick a feature from "Potential Next Features"
5. Or ask about any bugs/improvements needed

---

## Important Notes

- Python 3.9 venv at `venv_rag_2026/`
- All processing is local (no cloud APIs)
- LM Studio must be running before starting server
- BM25 index may need rebuild after adding documents: `python build_bm25_index.py`
- Spelling index rebuilds on startup or via `POST /api/spelling/rebuild`

---

**Ready to continue! All 15 features are working. What feature would you like to work on next?**
